{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Imports</h2>\n",
    "<ul>\n",
    "    <li>Pandas</li>\n",
    "    <li>Numpy</li>\n",
    "    <li>Matplotlib</li>\n",
    "    <li>Seaborn</li>\n",
    "    <li>Scikit-Learn</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import copy\n",
    "\n",
    "# Scikit_Learn imports\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load data</h2>\n",
    "<ul>\n",
    "    <li>Load train data</li>\n",
    "    <li>Load test data</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./Homework_04/Dataset/train.csv')\n",
    "X_test = pd.read_csv('./Homework_04/Dataset/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preprocessing</h2>\n",
    "<ul>\n",
    "    <li>Normalize</li>\n",
    "    <li>Handle missing values (already done)</li>\n",
    "    <li>Handle categorical values (already done)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_test = scalar.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>PCA</h2>\n",
    "<h5>Apply PCA using repeatedKfolds and then inverse transform the images and finally compute MSE and plot boxplots</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=500 must be between 0 and min(n_samples, n_features)=240 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\tuts\\Machine_Learning_Fall_1402\\BabaAli\\Projects\\ML_project_no4\\Q2.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/tuts/Machine_Learning_Fall_1402/BabaAli/Projects/ML_project_no4/Q2.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Apply PCA\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/tuts/Machine_Learning_Fall_1402/BabaAli/Projects/ML_project_no4/Q2.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m pca \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39mdimension)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/tuts/Machine_Learning_Fall_1402/BabaAli/Projects/ML_project_no4/Q2.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m X_train_fold_reduced \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39;49mfit_transform(X_train_fold)  \u001b[39m# Fit transform on 80% of the train set\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/tuts/Machine_Learning_Fall_1402/BabaAli/Projects/ML_project_no4/Q2.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m X_validation_fold_reduced \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39mtransform(X_validation_fold)  \u001b[39m# Transform validation set \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/tuts/Machine_Learning_Fall_1402/BabaAli/Projects/ML_project_no4/Q2.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m X_train_fold_reconstructed \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39minverse_transform(X_train_fold_reduced)  \u001b[39m# Reconstruct the train part again\u001b[39;00m\n",
      "File \u001b[1;32me:\\tuts\\Machine_Learning_Fall_1402\\BabaAli\\Projects\\ML_project_no4\\.env\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32me:\\tuts\\Machine_Learning_Fall_1402\\BabaAli\\Projects\\ML_project_no4\\.env\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32me:\\tuts\\Machine_Learning_Fall_1402\\BabaAli\\Projects\\ML_project_no4\\.env\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:460\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    438\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    439\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \n\u001b[0;32m    441\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 460\u001b[0m     U, S, Vt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[0;32m    461\u001b[0m     U \u001b[39m=\u001b[39m U[:, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components_]\n\u001b[0;32m    463\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwhiten:\n\u001b[0;32m    464\u001b[0m         \u001b[39m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[1;32me:\\tuts\\Machine_Learning_Fall_1402\\BabaAli\\Projects\\ML_project_no4\\.env\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:510\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[39m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_svd_solver \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 510\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_full(X, n_components)\n\u001b[0;32m    511\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_svd_solver \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39marpack\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrandomized\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    512\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_truncated(X, n_components, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_svd_solver)\n",
      "File \u001b[1;32me:\\tuts\\Machine_Learning_Fall_1402\\BabaAli\\Projects\\ML_project_no4\\.env\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:524\u001b[0m, in \u001b[0;36mPCA._fit_full\u001b[1;34m(self, X, n_components)\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    521\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mn_components=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmle\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is only supported if n_samples >= n_features\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    522\u001b[0m         )\n\u001b[0;32m    523\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m n_components \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(n_samples, n_features):\n\u001b[1;32m--> 524\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    525\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mn_components=\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m must be between 0 and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmin(n_samples, n_features)=\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msvd_solver=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_components, \u001b[39mmin\u001b[39m(n_samples, n_features))\n\u001b[0;32m    528\u001b[0m     )\n\u001b[0;32m    530\u001b[0m \u001b[39m# Center data\u001b[39;00m\n\u001b[0;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: n_components=500 must be between 0 and min(n_samples, n_features)=240 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "# Define desired dimensions\n",
    "desired_dimensions = [500, 300, 200, 140, 100, 70, 45, 30, 15, 8, 3]\n",
    "\n",
    "# Final MSEs\n",
    "mse_errors = dict()\n",
    "\n",
    "# Start to fit\n",
    "for dimension in desired_dimensions:\n",
    "    # Define Repeated K Folds \n",
    "    cv = RepeatedKFold(n_repeats=10, n_splits=5, random_state=42)\n",
    "\n",
    "    # Shuffle the Training data\n",
    "    np.random.shuffle(X_train)\n",
    "\n",
    "    for train_index, validation_index in cv.split(X_train):\n",
    "        X_train_fold = X_train[train_index]\n",
    "    X_validation_fold = X_train[validation_index]\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=dimension)\n",
    "    X_train_fold_reduced = pca.fit_transform(X_train_fold)  # Fit transform on 80% of the train set\n",
    "    X_validation_fold_reduced = pca.transform(X_validation_fold)  # Transform validation set \n",
    "    X_train_fold_reconstructed = pca.inverse_transform(X_train_fold_reduced)  # Reconstruct the train part again\n",
    "    X_validation_fold_reconstructed = pca.inverse_transform(X_validation_fold_reduced)  # Reconstruct the validation part again\n",
    "\n",
    "    # Calculate MSE\n",
    "    mse_train_fold = MSE(X_train_fold, X_train_fold_reconstructed)\n",
    "    mse_validation_fold = MSE(X_validation_fold, X_validation_fold_reconstructed)\n",
    "\n",
    "    # Store MSE of validation and train folds\n",
    "    if dimension not in mse_errors:\n",
    "        mse_errors[dimension] = {'train': [copy.deepcopy(mse_train_fold)], 'validation': [copy.deepcopy(mse_validation_fold)]}\n",
    "    elif dimension in mse_errors:\n",
    "        mse_errors[dimension]['train'].append(copy.deepcopy(mse_train_fold))\n",
    "        mse_errors[dimension]['validation'].append(copy.deepcopy(mse_validation_fold))\n",
    "    else:\n",
    "        raise Exception(\"ERROR\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
